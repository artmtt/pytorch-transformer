[tool.poetry]
name = "pytorch-transformer"
version = "0.1.0"
description = "PyTorch implementation of the Transformer model described in the Attention Is All You Need paper by Vaswani et al. (2017/2023)"
authors = ["artmtt (https://github.com/artmtt)"]
license = "MIT"
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.12"
ipykernel = "^6.29.5"
pandas = "^2.2.3"
matplotlib = "^3.10.0"
seaborn = "^0.13.2"

[tool.poetry.group.torch-cpu]
optional = true

[tool.poetry.group.torch-cpu.dependencies]
torch = "^2.5.1"

[tool.poetry.group.torch-cuda]
optional = true

[tool.poetry.group.torch-cuda.dependencies]
torch = { version = "^2.5.1+cu121", source = "torch_cu121" }


[[tool.poetry.source]]
name = "torch_cu121"
url = "https://download.pytorch.org/whl/cu121"
priority = "explicit"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
